#Description about Neural Networks
This is a project where I create layers to relay information, which will help make predictions! In Neural Networks, you have an input layer, as many hidden layers as you want (optional but better) and an output layer. The input layer contains data about the input you have given the network. These inputs then relay the dot product between the inputs and the weights connecting the input and hidden layer. Then, for optimal performance, you want to apply an activation function, in this case, a sigmoid. Then, we take the values of the hidden layer and relay the dot product with the weights connecting the hidden and output layers. This is forward-propogation. Then, we go back, and determine what went wrong in the predictions. We see how wrong the output layer was, and how much the hidden layer contributed to the error. This is back-propogation. We repeat the process for a number of iterations, or epochs. In my neural network, I am using the XOR gate problem.
